{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preparing the Dataset\n",
    "\n",
    "<span style=\"color:red\">__This notebook uses three additional libraries called imblearn,xgboost and ipywidget. Kindly install, as it is used in the Ensemble Model Building__</span>\n",
    "\n",
    "<span style=\"color:red\">__A couple of Grid Search cells are set to markdown mode as they take extremely long time. These are marked with CAUTION!!! label. To execute them, the assessor must set them to Code. These cells can be skipped and the note book would still run.__</span>\n",
    "\n",
    "We import the relevant libraries as usual and upload the csv data into our dataframe __df__. The first step we take is to eliminate rows where recharge amount was 0 in both months __6 and 7__. We do this,because these samples would errorneously pull down our average calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style=\"darkgrid\")\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "df1=pd.read_csv('telecom_churn_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df1[~((df1['total_rech_amt_6']==0) & (df1['total_rech_amt_7']==0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Labelling the Classes\n",
    "\n",
    "Now that we have only non-zero values in total_rech_amt_6 and 7 , we calculate the 70th Percentile of the average of these two columns and call it __high_val_thd__ .<br>\n",
    "We retain only those rows, where the average of these two columns is greater than or equal to the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_val_thd=((df['total_rech_amt_6']+df['total_rech_amt_7'])/2).quantile(0.7)\n",
    "df=df[((df['total_rech_amt_6']+df['total_rech_amt_7'])/2)>=high_val_thd]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function __find_churn__ returns 1 if incoming/outgoing calls and 2G/3G Data is 0 for the month 9, else it reurns 0. The values returned are kept in a new column called __churn__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def find_churn(x):\n",
    "    mou= x.total_ic_mou_9+x.total_og_mou_9+x.vol_2g_mb_9+x.vol_3g_mb_9\n",
    "    if mou==0:\n",
    "        y=1\n",
    "    else:\n",
    "        y=0\n",
    "    return y\n",
    "\n",
    "df['churn']=df.apply(find_churn,axis=1)\n",
    "print(df['churn'].value_counts())\n",
    "fig1, ax1 = plt.subplots(figsize=(5, 4))\n",
    "ax1.set_title('Fig 1 Class Imbalance', fontsize=14)\n",
    "ax1 = sns.countplot(x=\"churn\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Straight up, we see that there's a data imbalance. Churn cases is merely 10% of non-curn cases. Overall churn rate is at 8.6%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Removing Irrelevant Columns\n",
    "\n",
    "As stated in the guidelines, we can now remove all columns with the ___9__ suffix. <br>\n",
    "The columns Mobile Number and Circle ID are also irrelevant.<br>\n",
    "There is one feature __Volume Based Charging 3G__ from Jun to September. Since we are supposed to get rid of Sept ( Month 9 ) data, we remove __sep_vbc_3g__ as well \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_9=[ i for i in df.columns if i.find('_9')!=-1]\n",
    "df.drop(cols_with_9,inplace=True,axis=1)\n",
    "df.drop(['mobile_number', 'circle_id','sep_vbc_3g'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 EDA\n",
    "\n",
    "We are now in a position to assess the percentage of missing value in the dataframe. In the next cell , we present the percent of missing values only for columns that have missing entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_vals=df.isna().sum()!=0\n",
    "(round(100*df.isna().sum()/29034,2))[mis_vals]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Derived Feature MOU\n",
    "\n",
    "There are 90 variables related to MOU ( Minutes of Usage ) with the following characteritics.<br>\n",
    "\n",
    "- The MOU for __T to O__ is either 0 or missing for all rows, irrespective of incoming/outgoing or STD calls.\n",
    "- Then there are 29 MOU variables , one each for the months 6,7 and 8\n",
    "- We will use some domain research to establish the relationship with them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calls from Operator T to Other operator fixed line is either 0 or missing !!\n",
    "# So we might as well delete them, but let us check all the t2o mou features.\n",
    "\n",
    "t_2_o=['loc_og_t2o_mou','std_og_t2o_mou','loc_ic_t2o_mou']\n",
    "for i in t_2_o:\n",
    "    print(df[i].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On further study , we notice that for outgoing calls , the local and std are sum of few components.<br>\n",
    "\n",
    "$ loc\\_og\\_t2t + loc\\_og\\_t2m + loc\\_og\\_t2f = loc\\_og\\_mou  $ <br>\n",
    "$ std\\_og\\_t2t + std\\_og\\_t2m + std\\_og\\_t2f + std\\_og\\_t2c = std\\_og\\_mou  $ <br>\n",
    "$ loc\\_og\\_mou + std\\_og\\_mou + spl\\_o\\_mou + isd\\_og\\_mou + og\\_others = total\\_og\\_mou $\n",
    "\n",
    "Similarly , for incoming calls\n",
    "\n",
    "$ loc\\_ic\\_t2t + loc\\_ic\\_t2m + loc\\_ic\\_t2f = loc\\_ic\\_mou $ <br>\n",
    "$ std\\_ic\\_t2t + std\\_ic\\_t2m + std\\_ic\\_t2f + std\\_ic\\_t2o = std\\_ic\\_mou $ <br>\n",
    "$ loc\\_ic\\_mou + std\\_ic\\_mou + spl\\_ic\\_mou + isd\\_ic\\_mou + ic\\_others = total\\_ic\\_mou $ <br>\n",
    "\n",
    "This means , there's some multi-collinearity inbuilt in the features. We can get rid of the following features as their totals are available in the right hand side of the equations above<br>\n",
    "- t2t,t2m,t2f for local incoming and outgoing calls.\n",
    "- t2t,t2m,t2f,t2o,t2c for std incoming and outgoing calls.\n",
    "- if we keep the total MOU for Incoming, Outgoing, STD, Special, ISD and Others, then we do not need to retain total_og_mou and total_ic_mou "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=['og_t2t','og_t2m','og_t2f','og_t2o','ic_t2t','ic_t2m',\n",
    "   'ic_t2f','ic_t2o','std_og_t2c','std_og_t2o','total_og_mou','total_ic_mou']\n",
    "\n",
    "# if any columns contain the sub-strings in the list above, we append them to our\n",
    "# list del_mou, then we delete these columns.\n",
    "\n",
    "del_mou=[]\n",
    "for col in df.columns:\n",
    "    if any(c in col for c in x):\n",
    "        del_mou.append(col)\n",
    "\n",
    "df.drop(del_mou,inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's one ominous feature __t2c__ referring calls to Customer Care. We'll retain __loc_og_t2c_mou__ as this may indicate customer frustration, if they make too many calls of this category in the __action__ period.<br>\n",
    "\n",
    "We will now prepare a list of the mou features that we retained. We also need to add incoming and outgoing __others__ to our list of mou features. <br>\n",
    "\n",
    "We will now replace all missing values with 0, signifying zero minutes of usage for the coresponding feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mou_cols=[i for i in df.columns if i.find('mou')>-1 or i.find('others')>-1]\n",
    "df.fillna({x:0 for x in mou_cols}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=len(mou_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we have a list of __Minutes of Usage__ features for month 6,7 and 8. The variable __n__ holds its length. For every mou ( incoming, outgoing, std, local etc ), we'll take the average of month 6-7 and calculate percentage increase/decrease in month 8. This will give us a sense of sharp increase or decrease of the mou.\n",
    "\n",
    "For Example <br>\n",
    "$ xi = mean ( onnet\\_mou\\_6,onnet\\_mou\\_7) $ <br>\n",
    "$ xf = onnet\\_mou\\_8 $ <br>\n",
    "$ delta = xf - xi $ <br>\n",
    "$ onnet\\_mou = \\frac { delta } {xi} $ <br>\n",
    "\n",
    "We repeat the same process for all mou features ( indicated below ). However, we also deal with division by 0 or 0/0 in the function declaration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_delta(row,*args):\n",
    "    xi=(row[args[0]]+row[args[1]])/2\n",
    "    xf=row[args[2]]\n",
    "    delta=xf-xi\n",
    "    \n",
    "    if xi!=0 and delta!=0:\n",
    "        return delta/xi\n",
    "    \n",
    "    # deal with division by 0\n",
    "    elif xi==0 and delta!=0:\n",
    "        return 1\n",
    "    \n",
    "    # deal with 0 divided by 0 \n",
    "    elif xi==0 and delta==0:\n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "        return delta/xi\n",
    "    \n",
    "printmd(\"***Our New MOU Features***\")\n",
    "for a in range(0,n,3):\n",
    "    col_name=mou_cols[a][:-2]\n",
    "    print(col_name)\n",
    "    \n",
    "    df[col_name]=df.apply(cal_delta,args=(mou_cols[a],mou_cols[a+1],mou_cols[a+2]),axis=1)\n",
    "\n",
    "# We do not need the original mou features now\n",
    "\n",
    "df.drop(mou_cols,inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Derived Feature from Data Volume\n",
    "\n",
    "Turning our attention to the data usage in 2G and 3G to explore if there is any sharp decline in data usage from month 6-7 to month 8.<br>\n",
    "Before that , we check , if there are any missing data !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a list of features having 2G and 3G data usage in Megabytes\n",
    "data_vols=['vol_2g_mb_6','vol_2g_mb_7','vol_2g_mb_8','vol_3g_mb_6','vol_3g_mb_7','vol_3g_mb_8']\n",
    "\n",
    "# Are there any missing values ??\n",
    "df[data_vols].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is another caveat ,in terms of data usage. There are users , who haven't used data at all in the 3 months. For such users the difference of usage from months 6-7 to month 8 will always be zero. So ,we introduce another fetaure __Data_User__ , that is set to 0 or 1 depending upon the subscriber being a data user or not. This feature may turn out to be useful when we attempt a decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A temporary column Temp having the sum of 2G and 3G data Volume\n",
    "df['Temp']=df[['vol_2g_mb_6','vol_2g_mb_7','vol_2g_mb_8','vol_3g_mb_6','vol_3g_mb_7','vol_3g_mb_8']].sum(axis=1)\n",
    "\n",
    "# The function returns 0 if the total data volume in months 6,7,8 is zero.\n",
    "def data_user(row):\n",
    "    x=row['Temp']\n",
    "    if x==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "df['Data_User']=df.apply(data_user,axis=1)\n",
    "df.drop('Temp',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derived Features vol_2g_mb and vol_3g_mb\n",
    "\n",
    "df['vol_2g_mb']=df.apply(cal_delta,args=('vol_2g_mb_6','vol_2g_mb_7','vol_2g_mb_8'),axis=1)\n",
    "df.drop(['vol_2g_mb_6','vol_2g_mb_7','vol_2g_mb_8'],inplace=True,axis=1)\n",
    "\n",
    "df['vol_3g_mb']=df.apply(cal_delta,args=('vol_3g_mb_6','vol_3g_mb_7','vol_3g_mb_8'),axis=1)\n",
    "df.drop(['vol_3g_mb_6','vol_3g_mb_7','vol_3g_mb_8'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having dealt with the data volume __2G and 3G__ features, we notice that the corresponding data arpu features will always be zero , when data volume is zero for that month. <br>\n",
    "\n",
    "The converse may not be true. Thus, all missing values for arpu 2G and 3G can be replaced by 0. Furthermore , we derive two features arpu_3G and arpu_2g which are difference of the month 8 and mean of month 6-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of arpu 2G and 3G Features and then fill missing values with 0.\n",
    "\n",
    "arpu_3g=['arpu_3g_6','arpu_3g_7','arpu_3g_8']\n",
    "df.fillna({x:0 for x in arpu_3g}, inplace=True)\n",
    "arpu_2g=['arpu_2g_6','arpu_2g_7','arpu_2g_8']\n",
    "df.fillna({x:0 for x in arpu_2g}, inplace=True)\n",
    "\n",
    "# Derived Features arpu_2g and arpu_3g\n",
    "df['arpu_3g']=df.apply(cal_delta,args=('arpu_3g_6','arpu_3g_7','arpu_3g_8'),axis=1)\n",
    "df.drop(['arpu_3g_6','arpu_3g_7','arpu_3g_8'],inplace=True,axis=1)\n",
    "\n",
    "df['arpu_2g']=df.apply(cal_delta,args=('arpu_2g_6','arpu_2g_7','arpu_2g_8'),axis=1)\n",
    "df.drop(['arpu_2g_6','arpu_2g_7','arpu_2g_8'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Derived Feature Data Recharge Patterns\n",
    "\n",
    "We now look at the data recharge patterns. Note that:\n",
    "\n",
    "$ total\\_rech\\_data = count\\_rech\\_3g + count\\_rech\\_2g $\n",
    "\n",
    "We cam delete the features on the right hand side of the equation and use only __total_rech_data__. <br>\n",
    "\n",
    "These features indicate, how many times did the customer perform a recharge. We also have the average recharge amount per month. Thus, if we multiply the __total_rech_data__ with __av_rech_amt_data__ , we should get the total recharge amount for data in a particular month.\n",
    "\n",
    "$ total\\_rech\\_data\\_amt\\_6 = total\\_rech\\_data\\_6 * av\\_rech\\_amt\\_data\\_6 $\n",
    "\n",
    "We do this , for months 7 and 8. Then we use the same method as above to check if month 8 shows sharp degradation from average of 6 and 7 or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate the recharge amount in each month\n",
    "df['total_rech_data_amt_6']=df['total_rech_data_6']*df['av_rech_amt_data_6']\n",
    "df['total_rech_data_amt_7']=df['total_rech_data_7']*df['av_rech_amt_data_7']\n",
    "df['total_rech_data_amt_8']=df['total_rech_data_8']*df['av_rech_amt_data_8']\n",
    "\n",
    "# This creates a feature total_rech_data_amt, which detects any sudden change from mean of\n",
    "# month 6 and 7 to month 8\n",
    "\n",
    "df['total_rech_data_amt']=df.apply(cal_delta,args=('total_rech_data_amt_6','total_rech_data_amt_7','total_rech_data_amt_8'),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rech_cols=['total_rech_data_6', 'total_rech_data_7',\n",
    "       'total_rech_data_8', 'max_rech_data_6', 'max_rech_data_7',\n",
    "       'max_rech_data_8', 'count_rech_2g_6', 'count_rech_2g_7',\n",
    "       'count_rech_2g_8', 'count_rech_3g_6', 'count_rech_3g_7',\n",
    "       'count_rech_3g_8', 'av_rech_amt_data_6', 'av_rech_amt_data_7',\n",
    "       'av_rech_amt_data_8','total_rech_data_amt_6','total_rech_data_amt_7','total_rech_data_amt_8']\n",
    "\n",
    "df['total_rech_data_amt'].fillna(0,inplace=True)\n",
    "df.drop(data_rech_cols,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Derived Feature Recharge and ARPU\n",
    "\n",
    "We will now use the same argument to derive features pertaining to Recharge and ARPU. The key idea is to derive a feature that captures any sudden increase/decrease in the feature in month 8 compared to month 6 & 7. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derived Feature arpu\n",
    "\n",
    "df['arpu']=df.apply(cal_delta,args=('arpu_6','arpu_7','arpu_8'),axis=1)\n",
    "df.drop(['arpu_6','arpu_7','arpu_8'],inplace=True,axis=1)\n",
    "\n",
    "# Derived Feature total_rech_num\n",
    "df['total_rech_num']=df.apply(cal_delta,args=('total_rech_num_6','total_rech_num_7','total_rech_num_8'),axis=1)\n",
    "df.drop(['total_rech_num_6','total_rech_num_7','total_rech_num_8'],inplace=True,axis=1)\n",
    "\n",
    "# Derived Feature total_rech_amt\n",
    "df['total_rech_amt']=df.apply(cal_delta,args=('total_rech_amt_6','total_rech_amt_7','total_rech_amt_8'),axis=1)\n",
    "df.drop(['total_rech_amt_6','total_rech_amt_7','total_rech_amt_8'],inplace=True,axis=1)\n",
    "\n",
    "# Derived Feature max_rech_amt\n",
    "df['max_rech_amt']=df.apply(cal_delta,args=('max_rech_amt_6','max_rech_amt_7','max_rech_amt_8'),axis=1)\n",
    "df.drop(['max_rech_amt_6','max_rech_amt_7','max_rech_amt_8'],inplace=True,axis=1)\n",
    "\n",
    "# Derived Feature last_day_rch_amt\n",
    "df['last_day_rch_amt']=df.apply(cal_delta,args=('last_day_rch_amt_6','last_day_rch_amt_7','last_day_rch_amt_8'),axis=1)\n",
    "df.drop(['last_day_rch_amt_6','last_day_rch_amt_7','last_day_rch_amt_8'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Derived Feature Data  Packs\n",
    "\n",
    "There are few features reated to different packs that customer can buy like Night Packs, Monthly 2G/3G, Sachet and Facebook packs.\n",
    "\n",
    "We will add all these feature packs for a given month and then detect any sharp change from month 6-7 to month 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace package features missing values by 0\n",
    "\n",
    "pack_cols=['night_pck_user_6','night_pck_user_7','night_pck_user_8','fb_user_6','fb_user_7','fb_user_8']\n",
    "df.fillna({x:0 for x in pack_cols}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The feature_pack_6 , 7 and 8 is a measure of any package bought in the respective month\n",
    "\n",
    "df['feature_pack_6']=df['night_pck_user_6']+df['monthly_2g_6']+df['sachet_2g_6']+df['monthly_3g_6']+df['sachet_3g_6']+df['fb_user_6']\n",
    "df['feature_pack_7']=df['night_pck_user_7']+df['monthly_2g_7']+df['sachet_2g_7']+df['monthly_3g_7']+df['sachet_3g_7']+df['fb_user_7']\n",
    "df['feature_pack_8']=df['night_pck_user_8']+df['monthly_2g_8']+df['sachet_2g_8']+df['monthly_3g_8']+df['sachet_3g_6']+df['fb_user_8']\n",
    "\n",
    "# Now we calculate the change in feature_packs in month 8 w.r.t to mean of month 6 and 7\n",
    "df['feature_pack']=df.apply(cal_delta,args=('feature_pack_6','feature_pack_7','feature_pack_8'),axis=1)\n",
    "\n",
    "rem_pak_cols=['night_pck_user_6','night_pck_user_7','night_pck_user_8','monthly_2g_6','monthly_2g_7',\n",
    "              'monthly_2g_8','sachet_2g_6','sachet_2g_7','sachet_2g_8','monthly_3g_6','monthly_3g_7',\n",
    "              'monthly_3g_8','sachet_3g_6','sachet_3g_7','sachet_3g_8','fb_user_6','fb_user_7','fb_user_8',\n",
    "              'feature_pack_6','feature_pack_7','feature_pack_8']\n",
    "\n",
    "df.drop(rem_pak_cols,inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Derived Feature Recharge Urgency\n",
    "\n",
    "We try to build a feature indicating whether the subscriber recharged in all three months or not. We provide weights 1,2and 3 to features __date_of_last_rech_6,7 & 8__. We build a feature called __Recharge Habit__, which is a sum of all three weights.<br>\n",
    "\n",
    "If an individual has re-charged in all three months, then the new feature has a value 1+2+3 = 6. We follow the same approach for __date_of_last_rech_data_6,7 & 8__ and build a  feature __Recharge Habit data__.<br>\n",
    "\n",
    "With these two features, we can delete the last recharge date columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=df['date_of_last_rech_6'].isna()\n",
    "df['date_of_last_rech_6'][~mask]=1\n",
    "\n",
    "mask=df['date_of_last_rech_7'].isna()\n",
    "df['date_of_last_rech_7'][~mask]=2\n",
    "\n",
    "mask=df['date_of_last_rech_8'].isna()\n",
    "df['date_of_last_rech_8'][~mask]=3\n",
    "\n",
    "pack_cols=['date_of_last_rech_6','date_of_last_rech_7','date_of_last_rech_8']\n",
    "df.fillna({x:0 for x in pack_cols}, inplace=True)\n",
    "\n",
    "df['Recharge Habit']=df['date_of_last_rech_6']+df['date_of_last_rech_7']+df['date_of_last_rech_8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=df['date_of_last_rech_data_6'].isna()\n",
    "df['date_of_last_rech_data_6'][~mask]=1\n",
    "\n",
    "mask=df['date_of_last_rech_data_7'].isna()\n",
    "df['date_of_last_rech_data_7'][~mask]=2\n",
    "\n",
    "mask=df['date_of_last_rech_data_8'].isna()\n",
    "df['date_of_last_rech_data_8'][~mask]=3\n",
    "\n",
    "pack_cols=['date_of_last_rech_data_6','date_of_last_rech_data_7','date_of_last_rech_data_8']\n",
    "df.fillna({x:0 for x in pack_cols}, inplace=True)\n",
    "\n",
    "df['Recharge Habit data']=df['date_of_last_rech_data_6']+df['date_of_last_rech_data_7']+df['date_of_last_rech_data_8']\n",
    "\n",
    "df.drop(['date_of_last_rech_6','date_of_last_rech_7','date_of_last_rech_8','date_of_last_rech_data_6',\n",
    "        'date_of_last_rech_data_7','date_of_last_rech_data_8','last_date_of_month_6','last_date_of_month_7',\n",
    "        'last_date_of_month_8'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Derived Feature Volume Based Charging\n",
    "\n",
    "This is the last derived feature for __VBC_3G__. Just like we did above, we take the mean of months 6 and 7 and subtarct it from month 8. Our new feature is __vbc_3g__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbc_cols=['aug_vbc_3g','jul_vbc_3g','jun_vbc_3g']\n",
    "df.fillna({x:0 for x in vbc_cols}, inplace=True)\n",
    "\n",
    "df['vbc_3g']=df.apply(cal_delta,args=('jun_vbc_3g','jul_vbc_3g','aug_vbc_3g'),axis=1)\n",
    "df.drop(['aug_vbc_3g','jul_vbc_3g','jun_vbc_3g'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Outlier Treatment\n",
    "\n",
    "We've reduced the feature set to a mere 31 ( 32 with class label ). With such low number of features ,there's no point in exploring PCA. We will manage the rest of the problem with RFE and Random Forest Inspired Feature Importance. <br>\n",
    "\n",
    "However, before we proceed with model , we'll treat the outliers. Since we've a very low percentage of positive classes, we'll not remove outliers, but we'll cap them. <br>\n",
    "\n",
    "__Also , we'll limit the outlier capping to only those columns which represent a fraction of change from mean(Jun,Jul) to Aug.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_outliers=['aon', 'onnet_mou', 'offnet_mou', 'roam_ic_mou', 'roam_og_mou',\n",
    "       'loc_og_t2c_mou', 'loc_og_mou', 'std_og_mou', 'isd_og_mou',\n",
    "       'spl_og_mou', 'og_others', 'loc_ic_mou', 'std_ic_mou', 'spl_ic_mou',\n",
    "       'isd_ic_mou', 'ic_others', 'vol_2g_mb', 'vol_3g_mb',\n",
    "       'arpu_3g', 'arpu_2g', 'total_rech_data_amt', 'arpu', 'total_rech_num',\n",
    "       'total_rech_amt', 'max_rech_amt', 'last_day_rch_amt','vbc_3g']\n",
    "\n",
    "for col in rem_outliers:\n",
    "    #if col.find('mou')>-1:\n",
    "        #print(col)\n",
    "    qntl = df[col].quantile([0.25,0.75]).values\n",
    "    iqr=qntl[1]-qntl[0]\n",
    "    df[col][df[col] >= (qntl[1]+(1.5*iqr))] = (qntl[1]+(1.5*iqr))\n",
    "    df[col][df[col] <= (qntl[0]-(1.5*iqr))] = (qntl[0]-(1.5*iqr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 RFE\n",
    "\n",
    "We have reduced our features to 31 , but we can still explore the best set of features. So the best way to approach this is to select a small set of features from this pool of variables using RFE.<br>\n",
    "\n",
    "We'll build our first base model using Logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "import statsmodels.api as sm\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the labels from the dataset\n",
    "y=df.churn\n",
    "X=df.drop('churn',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,train_size=0.7,random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to run RFE to select top 20 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "rfe = RFE(logreg, 20)             \n",
    "rfe = rfe.fit(X_train, y_train)\n",
    "list(zip(X_train.columns, rfe.support_, rfe.ranking_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We retain only those features in X_train that've been selected by RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the TRUE variables from RFE\n",
    "x=list(zip(X_train.columns,rfe.support_,rfe.ranking_))\n",
    "rfe_vars=[i[0] for i in x if i[1]==True]\n",
    "X_train_rfe = X_train[rfe_vars]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">__The following cell shows 9 variables being removed in one go. However, this was actually done  sequentially to deal with high VIF and p-values>0.05. Only after that , these vriables have been decided to be removed. This way, we are avoiding multiple iterations in the notebook__</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This list was arrived at, after multiple iterations.\n",
    "\n",
    "high_vif_p_val=['Recharge Habit data','og_others','arpu','ic_others','total_rech_data_amt',\n",
    "                  'loc_og_mou','loc_og_t2c_mou','spl_og_mou','total_rech_num']\n",
    "\n",
    "for feature in high_vif_p_val:\n",
    "    if feature in X_train_rfe.columns:\n",
    "        X_train_rfe.drop(feature,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Logistic Regression Model\n",
    "\n",
    "We must bear in mind that , this is a grossly imbalanced dataset. Therefore we must focus on __Recall__ so that the most potential cases of churns ( True Positives ) are captured.\n",
    "\n",
    "We have reduced our features to 31 , but we can still explore the best set of features. So the best way to approach this is to select a small set of features from this pool of variables using RFE.<br>\n",
    "\n",
    "We'll build our first base model using Logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X_train_rfe)\n",
    "logm2 = sm.GLM(y_train, X_train_sm, family = sm.families.Binomial())\n",
    "log_reg= logm2.fit()\n",
    "log_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIF assessment of the 13 variables shows decent values and we've practically eliminated multi-collinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train_rfe.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train_rfe.values, i) for i in range(X_train_rfe.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now evaluate the model with a default probability of 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = log_reg.predict(X_train_sm)\n",
    "y_train_pred_final = pd.DataFrame({'Converted':y_train.values, 'Conversion_Prob':y_train_pred})\n",
    "y_train_pred_final['Predicted'] = y_train_pred_final.Conversion_Prob.map(lambda x: 1 if x > 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "confusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.Predicted )\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.Predicted)\n",
    "printmd('**Train Set Accuracy {:.3f} %**'.format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, since the most important aspect of this model is to detect potential churn cases. So we must find the best probability to get the highest Recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create columns with different probability cutoffs \n",
    "\n",
    "numbers = [float(x)/10 for x in range(10)]\n",
    "for i in numbers:\n",
    "    y_train_pred_final[i]= y_train_pred_final.Conversion_Prob.map(lambda x: 1 if x > i else 0)\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "for i in num:\n",
    "    cm1 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final[i] )\n",
    "    total1=sum(sum(cm1))\n",
    "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "    \n",
    "    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
    "print(cutoff_df)\n",
    "cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\n",
    "plt.title('Fig 2 Finding The Sweet Spot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we need to choose the threshold of 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion2 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final[0.1] )\n",
    "TP = confusion2[1,1] # true positive \n",
    "TN = confusion2[0,0] # true negatives\n",
    "FP = confusion2[0,1] # false positives\n",
    "FN = confusion2[1,0] # false negatives\n",
    "\n",
    "printmd('**Train Set Results**')\n",
    "printmd('**Sensitivity, TPR or Recall {:.3f} %**'.format(100*TP/(TP+FN)))\n",
    "printmd('**Specitivity {:.3f} %**'.format(100*TN/(TN+FP)))\n",
    "printmd('**FPR {:.3f} %**'.format(100*FP/ float(TN+FP)))\n",
    "printmd('**Precision {:.3f} %**'.format(100*TP/(TP+FP)))\n",
    "printmd('**Accuracy {:.3f} %**'.format(100*(TP+TN)/(TP+FP+TN+FN)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now plot the ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_roc( actual, probs ):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n",
    "                                              drop_intermediate = False )\n",
    "    auc_score = metrics.roc_auc_score( actual, probs )\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Fig 3 ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    return None\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve( y_train_pred_final.Converted, y_train_pred_final.Conversion_Prob, drop_intermediate = False )\n",
    "draw_roc(y_train_pred_final.Converted, y_train_pred_final.Conversion_Prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Logistic Regression Test Set Result\n",
    "\n",
    "We have now established a baseline model with a Logistic Model. Let us test the model with the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_rfe=X_test[X_train_rfe.columns]\n",
    "X_test_sm = sm.add_constant(X_test_rfe)\n",
    "y_test_pred = log_reg.predict(X_test_sm)\n",
    "\n",
    "y_test_pred_rfe = pd.DataFrame({'Converted':y_test.values, 'Conversion_Prob':y_test_pred})\n",
    "y_test_pred_rfe['Predicted'] = y_test_pred_rfe.Conversion_Prob.map(lambda x: 1 if x > 0.1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion3 = metrics.confusion_matrix(y_test_pred_rfe.Converted, y_test_pred_rfe.Predicted )\n",
    "TP = confusion3[1,1] # true positive \n",
    "TN = confusion3[0,0] # true negatives\n",
    "FP = confusion3[0,1] # false positives\n",
    "FN = confusion3[1,0] # false negatives\n",
    "\n",
    "printmd('**Test Set Results**')\n",
    "printmd('**Recall {:.3f} %**'.format(100*TP/(TP+FN)))\n",
    "printmd('**Specitivity {:.3f} %**'.format(100*TN/(TN+FP)))\n",
    "printmd('**FPR {:.3f} %**'.format(100*FP/(TN+FP)))\n",
    "printmd('**Precision {:.3f} %**'.format(100*TP/(TP+FP)))\n",
    "printmd('**Accuracy {:.3f} %**'.format(100*(TP+TN)/(TP+FP+TN+FN)))\n",
    "\n",
    "# We Store These Results for comparison later\n",
    "results1=[100*TP/(TP+FN),100*TN/(TN+FP),100*FP/(TN+FP),100*TP/(TP+FP),100*(TP+TN)/(TP+FP+TN+FN)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ensemble Models\n",
    "\n",
    "### 5.1 Random Forest on RFE Features\n",
    "\n",
    "We now move on to a Random Forest Model. We use the same features that Logistic regression finally gave us after removing all multi-collinearity and retaining only significant p-values.  In order to arrive at the correct hyperparameters, we'll first establish the individual ranges for each hyperparameter. <br>\n",
    "\n",
    "Our objective is to figure out a rough range for <br>\n",
    "\n",
    "- max_depth\n",
    "- min_samples_leaf\n",
    "- min_samples_split\n",
    "- n_estimators\n",
    "- max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import linear_model, metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Find the Optimum Max Depth__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_depth': range(1, 50,5)}\n",
    "d_tree = DecisionTreeClassifier(criterion = \"gini\", class_weight='balanced', random_state = 100)\n",
    "\n",
    "# We use the rfe X_train that wefinally got from Logistic Model\n",
    "grid_max_depth = GridSearchCV(d_tree, param_grid,cv=5,scoring=\"recall\",return_train_score=True)\n",
    "grid_max_depth.fit(X_train_rfe,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = grid_max_depth.cv_results_\n",
    "\n",
    "fig4,ax4 = plt.subplots(1,1,figsize=(6,6))\n",
    "ax4.set_title('Fig 4 Optimum Max Depth', fontsize=12)\n",
    "ax4 = sns.lineplot(x=\"param_max_depth\", y=\"mean_train_score\", data=scores,label='Train Set')\n",
    "ax4 = sns.lineplot(x=\"param_max_depth\", y=\"mean_test_score\", data=scores,label='Test Set')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max Depth appears to be in the range of 5 to 10.\n",
    "\n",
    "__Find the Optimum Min Samples Leaf__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'min_samples_leaf': range(100, 800,50)}\n",
    "d_tree = DecisionTreeClassifier(criterion = \"gini\", class_weight='balanced', random_state = 100)\n",
    "\n",
    "grid_min_samples_leaf = GridSearchCV(d_tree, param_grid,cv=5,scoring=\"recall\",return_train_score=True)\n",
    "grid_min_samples_leaf.fit(X_train_rfe,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = grid_min_samples_leaf.cv_results_\n",
    "\n",
    "fig5,ax5 = plt.subplots(1,1,figsize=(6,6))\n",
    "ax5.set_title('Fig 5 Optimum Min Samples Leaf', fontsize=12)\n",
    "ax5 = sns.lineplot(x=\"param_min_samples_leaf\", y=\"mean_train_score\", data=scores,label='Train Set')\n",
    "ax5 = sns.lineplot(x=\"param_min_samples_leaf\", y=\"mean_test_score\", data=scores,label='Test Set')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Min Samples Leaf appears to be in the range of 250 to 350\n",
    "\n",
    "__Find the Optimum Min Samples Split__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'min_samples_split': range(400, 900,50)}\n",
    "d_tree = DecisionTreeClassifier(criterion = \"gini\", class_weight='balanced', random_state = 100)\n",
    "\n",
    "grid_min_samples_split = GridSearchCV(d_tree, param_grid,cv=5,scoring=\"recall\",return_train_score=True)\n",
    "grid_min_samples_split.fit(X_train_rfe,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = grid_min_samples_split.cv_results_\n",
    "\n",
    "fig6,ax6 = plt.subplots(1,1,figsize=(6,6))\n",
    "ax6.set_title('Fig 6 Optimum Min Samples Split', fontsize=12)\n",
    "ax6 = sns.lineplot(x=\"param_min_samples_split\", y=\"mean_train_score\", data=scores,label='Train Set')\n",
    "ax6 = sns.lineplot(x=\"param_min_samples_split\", y=\"mean_test_score\", data=scores,label='Test Set')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Min Samples Split best setting appears to be within 700 to 800.\n",
    "\n",
    "The reamining two features n_estimators and max_features we'll test in the final Grid Search. For __max_features__ we will use square root of the number of features. Since in the Logistic Regression final model , we had 16 features, we'll use 5as the mid point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'max_depth': [5,10,15],\n",
    "    'min_samples_leaf': range(250, 300, 350),\n",
    "    'min_samples_split': range(600, 700, 800),\n",
    "    'n_estimators': [200,300,400], \n",
    "    'max_features': [3,5,10]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier(class_weight='balanced')\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, scoring='recall',\n",
    "                          cv = 3, n_jobs = -1,verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">__CAUTION !!!__</span><br>\n",
    "<span style=\"color:red\">__The following grid-search in markdown-mode takes approximately 2-3 minutes to execute. Reader can skip the next cell to move to the tuned model or convert the following cell to code from markdown__</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "### printing the optimal recall score and hyperparameters\n",
    "\n",
    "print('We can get Recall of',grid_search.best_score_,'using',grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that , we've found the best settings, let us build our final model based on the optimum settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(bootstrap=True,\n",
    "                             max_depth=10,\n",
    "                             min_samples_leaf=250, \n",
    "                             min_samples_split=600,\n",
    "                             max_features=10,\n",
    "                             n_estimators=200,class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.fit(X_train_rfe,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfc.predict(X_test[X_train_rfe.columns])\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_rf = metrics.confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion_rf[1,1] # true positive \n",
    "TN = confusion_rf[0,0] # true negatives\n",
    "FP = confusion_rf[0,1] # false positives\n",
    "FN = confusion_rf[1,0] # false negatives\n",
    "\n",
    "printmd('**Test Set Results**')\n",
    "printmd('**Sensitivity, TPR or Recall {:.3f} %**'.format(100*TP/(TP+FN)))\n",
    "printmd('**Specitivity {:.3f} %**'.format(100*TN/(TN+FP)))\n",
    "printmd('**FPR {:.3f} %**'.format(100*FP/ float(TN+FP)))\n",
    "printmd('**Precision {:.3f} %**'.format(100*TP/(TP+FP)))\n",
    "printmd('**Accuracy {:.3f} %**'.format(100*(TP+TN)/(TP+FP+TN+FN)))\n",
    "\n",
    "# We Store These Results for comparison later\n",
    "results2=[100*TP/(TP+FN),100*TN/(TN+FP),100*FP/(TN+FP),100*TP/(TP+FP),100*(TP+TN)/(TP+FP+TN+FN)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Random Forest on Entire Feature Set\n",
    "\n",
    "Before we proceed to the next Ensemble Model, let us try the Random Forest Model with the entire set of derived features and hyperparameters deduced above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_full_set= RandomForestClassifier(bootstrap=True,\n",
    "                             max_depth=10,\n",
    "                             min_samples_leaf=250, \n",
    "                             min_samples_split=600,\n",
    "                             max_features=10,\n",
    "                             n_estimators=200,class_weight='balanced')\n",
    "rfc_full_set.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_full_set = rfc_full_set.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_rf_full_set = metrics.confusion_matrix(y_test,y_pred_full_set)\n",
    "TP = confusion_rf_full_set[1,1] # true positive \n",
    "TN = confusion_rf_full_set[0,0] # true negatives\n",
    "FP = confusion_rf_full_set[0,1] # false positives\n",
    "FN = confusion_rf_full_set[1,0] # false negatives\n",
    "\n",
    "printmd('**Test Set Results**')\n",
    "printmd('**Sensitivity, TPR or Recall {:.3f} %**'.format(100*TP/(TP+FN)))\n",
    "printmd('**Specitivity {:.3f} %**'.format(100*TN/(TN+FP)))\n",
    "printmd('**FPR {:.3f} %**'.format(100*FP/ float(TN+FP)))\n",
    "printmd('**Precision {:.3f} %**'.format(100*TP/(TP+FP)))\n",
    "printmd('**Accuracy {:.3f} %**'.format(100*(TP+TN)/(TP+FP+TN+FN)))\n",
    "\n",
    "# We Store These Results for comparison later\n",
    "results3=[100*TP/(TP+FN),100*TN/(TN+FP),100*FP/(TN+FP),100*TP/(TP+FP),100*(TP+TN)/(TP+FP+TN+FN)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Slight Improvement in Recall and accuracy__\n",
    "\n",
    "### 5.3 Summarizing The Results So Far\n",
    "\n",
    "We have three models as of now. Let us see, how far we've come !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Compare=pd.DataFrame({'Metric':['Recall', 'Specificity', 'FPR','Precision','Accuracy'],\n",
    "                   'Logistic RFE':results1, 'Random Forest RFE':results2,\n",
    "                   'Random Forest All Features':results3})\n",
    "Compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest with all 31 features is performing the best. Looking at the business problem, our main agenda is to push Recall Higher. We'll build the next ensemble model based on these findings.<br>\n",
    "\n",
    "Let us see , what are the most important features declared by Random Forest.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_features=pd.DataFrame({'Features':X_train.columns,'Importance':rfc_full_set.feature_importances_})\n",
    "my_features.sort_values(by='Importance',ascending=False,inplace=True)\n",
    "\n",
    "fig7,ax7 = plt.subplots(1,1,figsize=(16,6))\n",
    "ax7.set_title('Fig 7 Random Forest Feature Importance', fontsize=14)\n",
    "ax7 = sns.barplot(x=\"Features\", y=\"Importance\", data=my_features)\n",
    "for tick in ax7.get_xticklabels():\n",
    "    tick.set_rotation(90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ensemble Model - Gradient Boost\n",
    "\n",
    "We skip __Adaboost__ and move straight to __Gradient Boost__. We use the top __15 Features__ as depicted in Figure 7 above and putting it in the list called final_features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the top 15 features from the Random Forest Algorithm Above\n",
    "\n",
    "final_features=list(my_features.iloc[0:15,0])\n",
    "rfe_features=X_train_rfe.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Handling Class Imbalance in GBoost\n",
    "\n",
    "One caveat is the feature imbalance in the dataset. We saw earlier that, barely 9-10% cases are Churns. We were able to handle this anomaly by using __class_weight='balanced'__ in our ealier classifiers.<br>\n",
    "\n",
    "The GB Classifier has no such option. Some research led the authors [here](https://www.kaggle.com/zksharp48/fraud-detection-gradient-boosting-oversampling/notebook) ,a kaggle project explaining oversampling using a library __imblearn__. <br>\n",
    "\n",
    "<span style=\"color:red\">__The following section mandates imblearn installation, otherwise the subsequent sections would fail to execute__</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please install imblearn !!\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# Apply SMOTE's\n",
    "kind = 'regular'\n",
    "smt = SMOTE(kind='regular')\n",
    "\n",
    "# We generate a synthetic dataset using oversampling\n",
    "X_res, y_res = smt.fit_sample(X_train[final_features], y_train)\n",
    "X_res=pd.DataFrame(X_res,columns=[final_features])\n",
    "print(\"Sampled Dataset has shape: \", X_res.shape)\n",
    "print(\"Number of Churn Cases (Real && Synthetic): \", np.sum(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_res,X_test_res,y_train_res,y_test_res=train_test_split(X_res,y_res,train_size=0.7,random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Hyperparameters for GBoost\n",
    "\n",
    "The following cell sets up the GridSearch set up for Gradient Boost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_grid_params = {'learning_rate': [0.02,0.05, 0.1],\n",
    "              'max_depth': [4, 6, 8],\n",
    "              'min_samples_leaf': [20, 50,100],\n",
    "              'max_features': ['auto','log2'] \n",
    "              }\n",
    "\n",
    "skv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False)\n",
    "\n",
    "\n",
    "gb_gs = GradientBoostingClassifier(n_estimators = 600)\n",
    "gb_clf = GridSearchCV(gb_gs,gb_grid_params,cv=skv.split(X_res, y_res),\n",
    "                      scoring='recall',verbose = 1,n_jobs=10,return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">__CAUTION !!!__</span>\n",
    "\n",
    "<span style=\"color:red\">__!!! The GradientBoost Grid search step in the cell below takes 60 minutes. The reader can skip this step to move to the model with tuned hyperparameters or convert the following cell to code from markdown !!!__</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gb_clf.fit(X_res, y_res)\n",
    "\n",
    "print('We can get Recall of',gb_clf.best_score_,'using',gb_clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Running the Tuned GBoost Model\n",
    "\n",
    "Now that, we've the optimum parameters for GBoost, we'll fit a model to  the oversampled dataset __X_train_res / y_train_res__ <br>\n",
    "\n",
    "Once the model is fit, we will attempt prediction on our original dataset with 15 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model with the optimum Hyperparameters, but on the oversampled dataset X_train_res, y_train_res\n",
    "\n",
    "gboost_final = GradientBoostingClassifier(n_estimators = 600,learning_rate=0.1,max_depth=8,min_samples_leaf=20,max_features= 'log2')\n",
    "gboost_final.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run prediction on the test set, that is NOT oversampled ( the actual test set ) with top 15 features\n",
    "\n",
    "y_pred_gb = gboost_final.predict(X_test[final_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_gboost = metrics.confusion_matrix(y_test,y_pred_gb)\n",
    "TP = confusion_gboost[1,1] # true positive \n",
    "TN = confusion_gboost[0,0] # true negatives\n",
    "FP = confusion_gboost[0,1] # false positives\n",
    "FN = confusion_gboost[1,0] # false negatives\n",
    "\n",
    "printmd('**Test Set Results**')\n",
    "printmd('**Sensitivity, TPR or Recall {:.3f} %**'.format(100*TP/(TP+FN)))\n",
    "printmd('**Specitivity {:.3f} %**'.format(100*TN/(TN+FP)))\n",
    "printmd('**FPR {:.3f} %**'.format(100*FP/ float(TN+FP)))\n",
    "printmd('**Precision {:.3f} %**'.format(100*TP/(TP+FP)))\n",
    "printmd('**Accuracy {:.3f} %**'.format(100*(TP+TN)/(TP+FP+TN+FN)))\n",
    "\n",
    "# We Store These Results for comparison later\n",
    "results4=[100*TP/(TP+FN),100*TN/(TN+FP),100*FP/(TN+FP),100*TP/(TP+FP),100*(TP+TN)/(TP+FP+TN+FN)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Ensemble Model - XG Boost\n",
    "\n",
    "This is our final model. We deal with data imbalance using two techniques.<br>\n",
    "\n",
    "- We use __RandmizedSearchCV__ and __StratifiedKFold__\n",
    "- We set scale_pos_weight=10 in the model, as that represents the ratio of the positive to negative class ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A parameter grid for XGBoost\n",
    "params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [4, 5,8]\n",
    "        }\n",
    "\n",
    "# Note that we've used RandmizedSearchCV and StratifiedKFold for finding the optimum parameters.\n",
    "xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, \n",
    "                    objective='binary:logistic',silent=True, nthread=1,scale_pos_weight=10)\n",
    "\n",
    "folds = 5\n",
    "param_comb = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring='recall',\n",
    "                                   n_jobs=4, cv=skf.split(X_train[final_features], y_train), verbose=3, random_state=1001 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<span style=\"color:red\">__CAUTION !!!__</span>\n",
    "\n",
    "<span style=\"color:red\">__!!! The XGBoost Grid search step in the cell below takes 3 minutes. The reader can skip this step to move to the model with tuned hyperparameters or or convert the following cell to code from markdown !!!__</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please set the cell to code for execution\n",
    "\n",
    "random_search.fit(X_train[final_features], y_train)\n",
    "print('We can get Recall of',random_search.best_score_,'using',random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running XGBoost with the optimum parameters\n",
    "\n",
    "xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',\n",
    "                    silent=True, nthread=1,subsample=1, min_child_weight=5, max_depth= 4,\n",
    "                    gamma= 5, colsample_bytree= 1,scale_pos_weight=10)\n",
    "\n",
    "xgb.fit(X_train[final_features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xg=xgb.predict(X_test[final_features])\n",
    "\n",
    "confusion_xgboost = metrics.confusion_matrix(y_test,y_pred_xg)\n",
    "TP = confusion_xgboost[1,1] # true positive \n",
    "TN = confusion_xgboost[0,0] # true negatives\n",
    "FP = confusion_xgboost[0,1] # false positives\n",
    "FN = confusion_xgboost[1,0] # false negatives\n",
    "\n",
    "printmd('**Test Set Results**')\n",
    "printmd('**Sensitivity, TPR or Recall {:.3f} %**'.format(100*TP/(TP+FN)))\n",
    "printmd('**Specitivity {:.3f} %**'.format(100*TN/(TN+FP)))\n",
    "printmd('**FPR {:.3f} %**'.format(100*FP/ float(TN+FP)))\n",
    "printmd('**Precision {:.3f} %**'.format(100*TP/(TP+FP)))\n",
    "printmd('**Accuracy {:.3f} %**'.format(100*(TP+TN)/(TP+FP+TN+FN)))\n",
    "\n",
    "# We Store These Results for comparison later\n",
    "results5=[100*TP/(TP+FN),100*TN/(TN+FP),100*FP/(TN+FP),100*TP/(TP+FP),100*(TP+TN)/(TP+FP+TN+FN)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Comparison\n",
    "\n",
    "We have now four models \n",
    "\n",
    "- __log_reg__ : Baseline Logistic Regression with 14 Features after removing Multi-collinearity and insignifcant features.\n",
    "- __rfc__ : Random Forest Model with the same set of features as above.\n",
    "- __rfc_full_set__ : Random Forest with full set of derived features.\n",
    "- __gboost_final__ : Gradient Boost Model with top 15 features identified by __rfc_full_set__.\n",
    "- __xgb__ : Gradient Boost Model with top 15 features identified by __rfc_full_set__.\n",
    "\n",
    "We'll first their performance on test sets, followed by ROC Curves on all 4 models. We expect to see __xgboost__ overshadowing the other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printmd('**Test Set Results**')\n",
    "\n",
    "Compare['GBoost with Top 15 Features']=results4\n",
    "Compare['XGBoost with Top 15 Features']=results5\n",
    "Compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 The ROC curves\n",
    "\n",
    "We can also comapre the overall perfromance of the model using the ROC Curves and reading the AUC for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'd require the predicted probabilities for each model.\n",
    "\n",
    "log_reg_proba = log_reg.predict(X_test_sm)\n",
    "rfc_proba=rfc.predict_proba(X_test[X_train_rfe.columns])[:, 1]\n",
    "rfc_full_set_proba=rfc_full_set.predict_proba(X_test)[:, 1]\n",
    "gboost_final_proba=gboost_final.predict_proba(X_test[final_features])[:, 1]\n",
    "xgboost_final_proba=xgb.predict_proba(X_test[final_features])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig8,ax8 = plt.subplots(1,1,figsize=(8,8))\n",
    "ax8.set_title('Fig 8 Model Comparison AUC', fontsize=14)\n",
    "\n",
    "# We use this function to deduce fpr,tpr, auc_score for all models\n",
    "def draw_roc2( actual, probs ):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,drop_intermediate = False )\n",
    "    auc_score = metrics.roc_auc_score( actual, probs )\n",
    "    \n",
    "    return fpr,tpr,round(auc_score,3)\n",
    "\n",
    "ax8 = sns.lineplot(x=[0,1], y=[0,1],label='1. Dumb Model -- 0.5',linewidth= 3,color='k')\n",
    "ax8.lines[0].set_linestyle(\"--\")\n",
    "\n",
    "fpr,tpr,auc_score=draw_roc2(y_test[0::10],log_reg_proba[0::10])\n",
    "ax8 = sns.lineplot(x=fpr, y=tpr,label='2. Logistic RFE -- {:.3f}'.format(auc_score),linewidth= 3)\n",
    "\n",
    "fpr,tpr,auc_score=draw_roc2(y_test[0::10],rfc_proba[0::10])\n",
    "ax8 = sns.lineplot(x=fpr, y=tpr,label='3. R Forest RFE -- {:.3f}'.format(auc_score),linewidth= 3)\n",
    "\n",
    "fpr,tpr,auc_score=draw_roc2(y_test[0::10],rfc_full_set_proba[0::10])\n",
    "ax8 = sns.lineplot(x=fpr, y=tpr,label='4. R Forest Full -- {:.3f}'.format(auc_score),linewidth= 3)\n",
    "\n",
    "fpr,tpr,auc_score=draw_roc2(y_test[0::10],gboost_final_proba[0::10])\n",
    "ax8 = sns.lineplot(x=fpr, y=tpr,label='5. G Boost 15 Top -- {:.3f}'.format(auc_score),linewidth= 3)\n",
    "\n",
    "fpr,tpr,auc_score=draw_roc2(y_test[0::10],xgboost_final_proba[0::10])\n",
    "ax8 = sns.lineplot(x=fpr, y=tpr,label='6. XG Boost 15 Top -- {:.3f}'.format(auc_score),linewidth= 3)\n",
    "\n",
    "ax8.legend().set_title('AUC Scores')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can strightaway pan the model __5.G Boost 15 Top__, as it has the lowest AUC and its Recall is merely 57%. This'll practically serve no purpose to capture potential churners.<br>\n",
    "\n",
    "Though, the maximum AUC=0.907 is registered for __3.Random Forest RFE Features__, but we've every reason to stick to  __6.XGBoost with Top 15 Features__ model. This is because , it has the lowest __FPR=11%__ and it has __Recall=80.4%__. This is only slightly worse than the __Random Forest All Features__ model, which has __Recall=84%__ but __FPR=54%__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Business Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that, we've chosen XGBoost with Top 15 Features as our final model, let us try to understand how these 15 features actually indicate a potential churner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ipywidgets import *\n",
    "n=len(final_features)-1\n",
    "\n",
    "printmd('***Use the Widget Below***')\n",
    "\n",
    "def h(x):\n",
    "    \n",
    "    fig9,ax9 = plt.subplots(1,1,figsize=(4, 4))\n",
    "    col=final_features[x]\n",
    "    \n",
    "    sns.boxplot(x=y, y=X[col], data=X,ax=ax9,linewidth=0.5,width=0.5)\n",
    "    ax9.set_title('Fig 9 {}'.format(col), fontsize=14)\n",
    "    return None\n",
    "\n",
    "interact(h, x=widgets.IntSlider(min=0, max=n, step=1, value=0));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please recall, most features have been converted to a fraction representing change in Aug , relative to mean of Jun and July. One such example is presented here again.\n",
    "\n",
    "For Example <br>\n",
    "$ xi = mean ( onnet\\_mou\\_6,onnet\\_mou\\_7) $ <br>\n",
    "$ xf = onnet\\_mou\\_8 $ <br>\n",
    "$ delta = xf - xi $ <br>\n",
    "$ onnet\\_mou = \\frac { delta } {xi} $ <br>\n",
    "\n",
    "\n",
    "From the sliding widget above, we can see that except __roam_og_mou__ and __feature_pack__ all others show a clear tendency towards churn, if there is huge reduction in them in Month 8 compared to mean of month 6 and 7. Thus, from a business perspective , if there is a sharp decline in the __action_phase__.<br>\n",
    "\n",
    "- __Local,STD Incoming Minutes of Usage:__ It seems, if there's a sharp decline , it most probably indicates that the subscriber has moved to a new number and has shared the new number to his contacts.\n",
    "- __Local, STD, Roaming Outgoing Minutes of Usage:__ Similarly, if the user has started using another operator, there's no reason why he would keep making outgoing calls.\n",
    "- __Onnet-Offnet Minutes of Usage:__ A decline in above factors will obviously affect the Onnet/Offnet Usage. This is just a euphemism for saying that the subscriber has stopped using the current number.\n",
    "- __ARPU:__ This is relatively simple to understand. The subscriber stopping revenue generating activity is a clear indication of him not using the services.\n",
    "- __Total, Maximum Recharge and Last Date recharge Amount :__ If a subscriber carries on his usual usage pattern, there is no reason for a sharp decline here in the action phase. However, if he his recharge pattern shows a sharp decline, its a caue of concern.\n",
    "- __Age on Network ( AON ):__ It seems that new users are more prone to changing the service provider. This is probably because , old users find it harder to update their contacts. That's why their stickiness is higher. __This is a big insight, indicating that new users must be made to stick to their current number__ for a certain period to ensure their loyalty. That probably explains operators giving away free Amazon Prime/ Netflix services for new users.\n",
    "- __Recahrge Habit Data:__ Please recall,  this fetaure is sum of thre weights 1,2 and 3. If a subscriber recharges all three months, this will be 1+2+3=6. Whereas, if he recharges in only Jun and July, then it would be 1+2+0=5. A figure less than 2 indicates that he hasn't recharges even once in Aug. This is an indicator of the fact, that the subscriber has probably lost interest."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
